[{"path":"https://jesusbutforgaypeople.github.io/snazzieR/articles/pls-overview.html","id":"overview-of-partial-least-squares-pls-regression","dir":"Articles","previous_headings":"","what":"Overview of Partial Least Squares (PLS) Regression","title":"PLS Overview","text":"snazzieR package implements Partial Least Squares regression support : NIPALS algorithm SVD-based method Beautiful console LaTeX output formatting","code":""},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/articles/pls-overview.html","id":"what-is-pls","dir":"Articles","previous_headings":"Overview of Partial Least Squares (PLS) Regression","what":"What is PLS?","title":"PLS Overview","text":"PLS regression dimension reduction technique projects predictors lower-dimensional space maximally explains covariance response variable(s). especially useful : Predictors highly collinear number predictors exceeds number observations","code":""},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/articles/pls-overview.html","id":"learn-more","dir":"Articles","previous_headings":"Overview of Partial Least Squares (PLS) Regression","what":"Learn More","title":"PLS Overview","text":"NIPALS Algorithm SVD Method Output Formatting","code":""},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/articles/pls-overview.html","id":"the-origins-of-pls","dir":"Articles","previous_headings":"Overview of Partial Least Squares (PLS) Regression","what":"The Origins of PLS","title":"PLS Overview","text":"story PLS begins snowy mountains Uppsala, Sweden. early 1960s, Herman Wold working method analyze relationship set predictors set responses. particularly interested case predictors highly collinear, made traditional regression methods unreliable. Wold’s solution use latent variable approach, extract small number latent variables predictors use predict responses. method later named Partial Least Squares (PLS). initial algorithm called “NILES” (Nonlinear Iterative Least Squares), later renamed “NIPALS” (Nonlinear Iterative Partial Least Squares). Coming background econometrics, cleanly independent predictors rare, Wold stranger challenges introduced multicollinearity. 1966, laid groundwork become PLS introducing iterative least squares method estimate principal components [11]. 1969, colleagues applied methods econometric problems including canonical correlation analysis fixed-point estimation [15]. PLS emerged extension PCA. reduce dimensionality preserving structure, PLS goes maximizing covariance predictors responses—making effective regression tool. Herman Wold; father PLS [10] 1975, Wold colleagues released formal description PLS algorithm applications increasingly large predictor spaces [13]. laid foundation -called “Basic Design” PLS late 1970s [14], provided formal treatment algorithm convergence. 1980s, PLS gained traction chemometrics, particularly spectroscopy chromatography. iterative NIPALS algorithm well-suited handling large variable sets missing data [16]. Software packages helped adoption, though theoretical work briefly stalled. changed 1990s resurgence PLS development, aided modern computing power. key moment came Sijmen de Jong’s 1993 publication SVD-based approach PLS [3], computed components instead iteratively. dramatically improved efficiency opened PLS large-scale applications genomics, proteomics, metabolomics [7]. Modern variants like sparse PLS kernel PLS emerged address high-dimensional nonlinear problems. rise R Python ecosystems, community-driven implementations made PLS accessible ever [8].  2000s, PLS found application neuroimaging (e.g., fMRI analysis [5]) later machine learning data mining kernel-based extensions [9]. toolkits matured, became staple classification, regression, feature extraction. Recent work integrates PLS Bayesian models, ensemble methods, even deep learning. example, Deep PLS methods combine interpretability powerful representation learning [6]. continued expansion, PLS remains one flexible powerful tools multivariate statistical analysis.","code":""},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/articles/pls-overview.html","id":"references","dir":"Articles","previous_headings":"Overview of Partial Least Squares (PLS) Regression","what":"References","title":"PLS Overview","text":"Abdi, H. (2010). Partial least squares regression projection latent structure regression (PLS regression). Technical report. University Texas Dallas. https://www.utdallas.edu/~herve/Abdi-PLS-pretty.pdf Abdi, H., & Williams, L. J. (2013). Partial least squares methods: Partial least squares correlation partial least square regression. Methods Molecular Biology, 930, 549–579. doi.org/10.1007/978-1-62703-059-5_23 de Jong, S. (1993). SIMPLS: alternative approach partial least squares regression. Chemometrics Intelligent Laboratory Systems, 18(3), 251–263. doi.org/10.1016/0169-7439(93)85002-X Ghosh, S., & Doshi-Velez, F. (2017). Model selection Bayesian neural networks via horseshoe priors. Journal Machine Learning Research, 20(1), 1–46. Krishnan, ., Williams, L. J., McIntosh, . R., & Abdi, H. (2011). Partial least squares (PLS) methods neuroimaging: tutorial review. NeuroImage, 56(2), 455–475. doi.org/10.1016/j.neuroimage.2010.07.034 Kong, X., & Ge, Z. (2023). Deep PLS: lightweight deep learning model interpretable efficient data analytics. IEEE Transactions Neural Networks Learning Systems, 34(11), 8923–8937. doi.org/10.1109/TNNLS.2022.3154090 Nguyen, D. V., & Rocke, D. M. (2002). Tumor classification partial least squares using microarray gene expression data. Bioinformatics, 18(1), 39–50. doi.org/10.1093/bioinformatics/18.1.39 Rohart, F., Gautier, B., Singh, ., & Lê Cao, K.-. (2017). mixOmics: R package ’omics feature selection multiple data integration. PLOS Computational Biology, 13(11), e1005752. doi.org/10.1371/journal.pcbi.1005752 Rosipal, R., & Trejo, L. J. (2001). Kernel partial least squares regression reproducing kernel Hilbert space. Journal Machine Learning Research, 2, 97–123. Wikipedia contributors. (2025, March 22). Herman Wold. Wikipedia. Wikipedia Link Wold, H. (1966). Estimation principal components related models iterative least squares. P. R. Krishnajah (Ed.), Multivariate analysis (pp. 391–420). Academic Press. Wold, H. (1973). Nonlinear iterative partial least squares (NIPALS) modelling: current developments. P. R. Krishnaiah (Ed.), Multivariate Analysis III (pp. 383–407). Academic Press. Wold, H. (1975). Soft modelling latent variables: non-linear iterative partial least squares (NIPALS) approach. Perspectives Probability Statistics (pp. 117–142). Academic Press. Wold, H. (1979). Model construction evaluation theoretical knowledge scarce: PLS approach latent variables. K. G. Jöreskog & H. Wold (Eds.), Systems indirect observation: Causality, structure, prediction (Vol. 2, pp. 47–74). North-Holland. Wold, H., & Lyttkens, E. (1969). Nonlinear iterative partial least squares (NIPALS) estimation procedures. Bulletin International Statistical Institute, 43, 29–51. Wold, S., Sjöström, M., & Eriksson, L. (1996). PLS-regression: basic tool chemometrics. Chemometrics Intelligent Laboratory Systems, 58(2), 109–130. doi.org/10.1016/S0169-7439(01)00155-1 Wright, K. (2017, October 27). NIPALS algorithm. R-Project.org. https://cran.r-project.org/web/packages/nipals/vignettes/nipals_algorithm.html","code":""},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Aidan J. Wagner. Author, maintainer.","code":""},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Wagner AJ (2025). snazzieR: Chic Sleek Functions Beautiful Statisticians. R package version 0.1.1, https://jesusbutforgaypeople.github.io/snazzieR/.","code":"@Manual{,   title = {snazzieR: Chic and Sleek Functions for Beautiful Statisticians},   author = {Aidan J. Wagner},   year = {2025},   note = {R package version 0.1.1},   url = {https://jesusbutforgaypeople.github.io/snazzieR/}, }"},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/index.html","id":"snazzier","dir":"","previous_headings":"","what":"snazzieR","title":"snazzieR","text":"linear models deserve better console output. sleek color palette kable styling make regression results look sharper . Includes support Partial Least Squares (PLS) regression via SVD NIPALS algorithms, along unified interface model fitting fabulous LaTeX console output formatting. See package manual https://github.com/JesusButForGayPeople/snazzieR/releases/download/v0.1.1/snazzieR_0.1.1.pdf.","code":""},{"path":[]},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/index.html","id":"reference","dir":"","previous_headings":"Site Navigation","what":"Reference","title":"snazzieR","text":"pls.regression() NIPALS Algorithm SVD Algorithm model.summary.table() model.equation() ANOVA.summary.table() eigen.summary() pls.summary() snazzieR.theme() colors color.ref()","code":""},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/ANOVA.summary.table.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a Summary Table for ANOVA Results — ANOVA.summary.table","title":"Generate a Summary Table for ANOVA Results — ANOVA.summary.table","text":"function creates summary table ANOVA results, including degrees freedom, sum squares, mean squares, F-values, p-values. table can output either LaTeX (PDF reports) plain text (console viewing).","code":""},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/ANOVA.summary.table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a Summary Table for ANOVA Results — ANOVA.summary.table","text":"","code":"ANOVA.summary.table(model, caption, latex = TRUE)"},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/ANOVA.summary.table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a Summary Table for ANOVA Results — ANOVA.summary.table","text":"model model object ANOVA results computed (e.g., output `lm()` `aov()`). caption character string used caption table. latex Logical; `TRUE`, returns LaTeX-formatted table using `kableExtra`. `FALSE`, prints plain-text version console.","code":""},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/ANOVA.summary.table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a Summary Table for ANOVA Results — ANOVA.summary.table","text":"`latex = TRUE`, LaTeX-formatted table object. `latex = FALSE`, prints summary table returns (invisibly).","code":""},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/ANOVA.summary.table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a Summary Table for ANOVA Results — ANOVA.summary.table","text":"","code":"# Fit a linear model model <- lm(mpg ~ wt + hp, data = mtcars)  # Generate a plain-text ANOVA summary table ANOVA.summary.table(model, caption = \"ANOVA Summary\", latex = FALSE) #>        Term Df    Sum.Sq   Mean.Sq   F.Value P.Value Signif. #> 1        wt  1 847.72525 847.72525 126.04109       0      :3 #> 2        hp  1  83.27418  83.27418  12.38133 0.00145      :) #> 3 Residuals 29 195.04775   6.72578                        :3"},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/NIPALS.pls.html","id":null,"dir":"Reference","previous_headings":"","what":"Partial Least Squares Regression via NIPALS (Internal) — NIPALS.pls","title":"Partial Least Squares Regression via NIPALS (Internal) — NIPALS.pls","text":"function called internally pls.regression intended used directly. Use pls.regression(..., calc.method = \"NIPALS\") instead. Performs Partial Least Squares (PLS) regression using NIPALS (Nonlinear Iterative Partial Least Squares) algorithm. method estimates latent components (scores, loadings, weights) iteratively updating X Y score directions convergence. suitable cases number predictors large predictors highly collinear.","code":""},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/NIPALS.pls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Partial Least Squares Regression via NIPALS (Internal) — NIPALS.pls","text":"","code":"NIPALS.pls(x, y, n.components = NULL)"},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/NIPALS.pls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Partial Least Squares Regression via NIPALS (Internal) — NIPALS.pls","text":"x numeric matrix data frame predictors (X). dimensions n × p. y numeric matrix data frame response variables (Y). dimensions n × q. n.components Integer specifying number PLS components extract. NULL, defaults qr(x)$rank.","code":""},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/NIPALS.pls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Partial Least Squares Regression via NIPALS (Internal) — NIPALS.pls","text":"list following elements: model.type Character string indicating model type (\"PLS Regression\"). T Matrix X scores (n × H). U Matrix Y scores (n × H). W Matrix X weights (p × H). C Matrix normalized Y weights (q × H). P_loadings Matrix X loadings (p × H). Q_loadings Matrix Y loadings (q × H). B_vector Vector regression scalars (length H), one component. coefficients Matrix regression coefficients original data scale (p × q). intercept Vector intercepts (length q). Always zero due centering. X_explained Percent total X variance explained component. Y_explained Percent total Y variance explained component. X_cum_explained Cumulative X variance explained. Y_cum_explained Cumulative Y variance explained.","code":""},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/NIPALS.pls.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Partial Least Squares Regression via NIPALS (Internal) — NIPALS.pls","text":"algorithm standardizes x y using z-score normalization. performs following n.components latent variables: Initializes random response score vector \\(u\\). Iteratively: Updates X weight vector \\(w = E^\\top u\\), normalized. Computes X score \\(t = E w\\), normalized. Updates Y loading \\(q = F^\\top t\\), normalized. Updates response score \\(u = F q\\). Repeats \\(t\\) converges tolerance threshold. Computes scalar regression coefficient \\(b = t^\\top u\\). Deflates residual matrices \\(E\\) \\(F\\) remove current component contribution. component extraction, final regression coefficient matrix \\(B_{original}\\) computed rescaled original data units. Explained variance also computed component-wise cumulatively.","code":""},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/NIPALS.pls.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Partial Least Squares Regression via NIPALS (Internal) — NIPALS.pls","text":"Wold, H., & Lyttkens, E. (1969). Nonlinear iterative partial least squares (NIPALS) estimation procedures. Bulletin International Statistical Institute, 43, 29–51.","code":""},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/NIPALS.pls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Partial Least Squares Regression via NIPALS (Internal) — NIPALS.pls","text":"","code":"if (FALSE) { # \\dontrun{ X <- matrix(rnorm(100 * 10), 100, 10) Y <- matrix(rnorm(100 * 2), 100, 2) model <- pls.regression(X, Y, n.components = 3, calc.method = \"NIPALS\") model$coefficients } # }"},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/SVD.pls.html","id":null,"dir":"Reference","previous_headings":"","what":"Partial Least Squares Regression via SVD (Internal) — SVD.pls","title":"Partial Least Squares Regression via SVD (Internal) — SVD.pls","text":"function called internally pls.regression intended used directly. Use pls.regression(..., calc.method = \"SVD\") instead. Performs Partial Least Squares (PLS) regression using Singular Value Decomposition (SVD) cross-covariance matrix. method estimates latent components identifying directions predictor response spaces maximize covariance, using leading singular vectors matrix \\(R = X^\\top Y\\).","code":""},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/SVD.pls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Partial Least Squares Regression via SVD (Internal) — SVD.pls","text":"","code":"SVD.pls(x, y, n.components = NULL)"},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/SVD.pls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Partial Least Squares Regression via SVD (Internal) — SVD.pls","text":"x numeric matrix data frame predictors (X). dimensions n × p. y numeric matrix data frame response variables (Y). dimensions n × q. n.components Integer specifying number PLS components extract. NULL, defaults qr(x)$rank.","code":""},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/SVD.pls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Partial Least Squares Regression via SVD (Internal) — SVD.pls","text":"list containing: model.type Character string indicating model type (\"PLS Regression\"). T Matrix predictor scores (n × H). U Matrix response scores (n × H). W Matrix predictor weights (p × H). C Matrix normalized response weights (q × H). P_loadings Matrix predictor loadings (p × H). Q_loadings Matrix response loadings (q × H). B_vector Vector scalar regression weights (length H). coefficients Matrix final regression coefficients original scale (p × q). intercept Vector intercepts (length q). zeros due centering. X_explained Percent total X variance explained component. Y_explained Percent total Y variance explained component. X_cum_explained Cumulative X variance explained. Y_cum_explained Cumulative Y variance explained.","code":""},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/SVD.pls.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Partial Least Squares Regression via SVD (Internal) — SVD.pls","text":"algorithm begins z-scoring x y (centering scaling unit variance). initial residual matrices set scaled values: E = X_scaled, F = Y_scaled. component h = 1, ..., H: Compute cross-covariance matrix \\(R = E^\\top F\\). Perform SVD \\(R = U D V^\\top\\). Extract first singular vectors: \\(w = U[,1]\\), \\(q = V[,1]\\). Compute scores: \\(t = E w\\) (normalized), \\(u = F q\\). Compute loadings: \\(p = E^\\top t\\), regression scalar \\(b = t^\\top u\\). Deflate residuals: \\(E \\gets E - t p^\\top\\), \\(F \\gets F - b t q^\\top\\). components extracted, post-processing step removes components zero regression weight. scaled regression coefficients computed using Moore–Penrose pseudoinverse loading matrix \\(P\\), rescaled original variable units.","code":""},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/SVD.pls.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Partial Least Squares Regression via SVD (Internal) — SVD.pls","text":"Abdi, H., & Williams, L. J. (2013). Partial least squares methods: Partial least squares correlation partial least square regression. Methods Molecular Biology (Clifton, N.J.), 930, 549–579. doi:10.1007/978-1-62703-059-5_23 de Jong, S. (1993). SIMPLS: alternative approach partial least squares regression. Chemometrics Intelligent Laboratory Systems, 18(3), 251–263. doi:10.1016/0169-7439(93)85002-X","code":""},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/SVD.pls.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Partial Least Squares Regression via SVD (Internal) — SVD.pls","text":"","code":"if (FALSE) { # \\dontrun{ X <- matrix(rnorm(100 * 10), 100, 10) Y <- matrix(rnorm(100 * 2), 100, 2) model <- pls.regression(X, Y, n.components = 3, calc.method = \"SVD\") model$coefficients } # }"},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/color.ref.html","id":null,"dir":"Reference","previous_headings":"","what":"Display a Color Reference Palette — color.ref","title":"Display a Color Reference Palette — color.ref","text":"function generates plot displaying predefined color palette color codes easy reference. palette includes shades Red, Orange, Yellow, Green, Blue, Purple, Grey.","code":""},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/color.ref.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Display a Color Reference Palette — color.ref","text":"","code":"color.ref()"},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/color.ref.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Display a Color Reference Palette — color.ref","text":"plot displaying color palette.","code":""},{"path":[]},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/color.ref.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Display a Color Reference Palette — color.ref","text":"","code":"color.ref()"},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/colors.html","id":null,"dir":"Reference","previous_headings":"","what":"SnazzieR Color Palette — colors","title":"SnazzieR Color Palette — colors","text":"collection named hex colors grouped hue tone. color available exported object (e.g., Red, Dark.Red).","code":""},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/colors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"SnazzieR Color Palette — colors","text":"","code":"color.list"},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/colors.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"SnazzieR Color Palette — colors","text":"color character string representing hex code. object class character length 1. object class list length 35.","code":""},{"path":[]},{"path":[]},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/eigen.summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize Eigenvalues and Eigenvectors of a Covariance Matrix — eigen.summary","title":"Summarize Eigenvalues and Eigenvectors of a Covariance Matrix — eigen.summary","text":"function computes eigenvalues eigenvectors given covariance matrix, ensures sign consistency eigenvectors, outputs either LaTeX table plaintext summary displaying results.","code":""},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/eigen.summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize Eigenvalues and Eigenvectors of a Covariance Matrix — eigen.summary","text":"","code":"eigen.summary(   cov.matrix,   caption = \"Eigenvectors of Covariance Matrix\",   space_after_caption = \"5mm\",   latex = TRUE )"},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/eigen.summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize Eigenvalues and Eigenvectors of a Covariance Matrix — eigen.summary","text":"cov.matrix square numeric matrix representing covariance matrix. caption character string specifying table caption (default: \"Eigenvectors Covariance Matrix\"). space_after_caption character string specifying space caption LaTeX (default: \"5mm\"). latex logical indicating whether output LaTeX table (default: TRUE). FALSE, prints plain text.","code":""},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/eigen.summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize Eigenvalues and Eigenvectors of a Covariance Matrix — eigen.summary","text":"LaTeX formatted table (latex = TRUE) plaintext console output (latex = FALSE).","code":""},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/eigen.summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize Eigenvalues and Eigenvectors of a Covariance Matrix — eigen.summary","text":"","code":"cov_matrix <- matrix(c(4, 2, 2, 3), nrow = 2) eigen.summary(cov_matrix, caption = \"Eigenvalues and Eigenvectors of Covariance Matrix\", latex = FALSE) #> == Eigenvalues and Eigenvectors of Covariance Matrix == #>  #> Eigenvalues: #> [1] 5.56155 1.43845 #>  #> Eigenvectors (columns correspond to eigenvalues): #>  #>       λ1         λ2 #> --------  --------- #>  0.78821   -0.61541 #>  0.61541    0.78821 #>  #> Total Variance: 7"},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/model.equation.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a Model Equation from a Linear Model — model.equation","title":"Generate a Model Equation from a Linear Model — model.equation","text":"function extracts formats equation linear model object. includes option return equation LaTeX-formatted string print console.","code":""},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/model.equation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a Model Equation from a Linear Model — model.equation","text":"","code":"model.equation(model, latex = TRUE)"},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/model.equation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a Model Equation from a Linear Model — model.equation","text":"model linear model object (e.g., output `lm()`). latex logical value indicating whether return LaTeX-formatted equation (default: TRUE). FALSE, equation printed console.","code":""},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/model.equation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a Model Equation from a Linear Model — model.equation","text":"`latex` TRUE, equation returned LaTeX code using `knitr::asis_output()`. FALSE, equation printed console.","code":""},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/model.equation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a Model Equation from a Linear Model — model.equation","text":"","code":"# Fit a linear model model <- lm(mpg ~ wt + hp, data = mtcars)  # Get LaTeX equation model.equation(model) #> [1] \"\\\\[\\\\text{mpg} = 37.227 - 3.878 (\\\\text{wt}) - 0.032 (\\\\text{hp})\\\\]\" #> attr(,\"class\") #> [1] \"knit_asis\" #> attr(,\"knit_cacheable\") #> [1] NA  # Print equation to console model.equation(model, latex = FALSE) #> mpg = 37.227 - 3.878 (wt) - 0.032 (hp)"},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/model.summary.table.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a Summary Table for a Linear Model — model.summary.table","title":"Generate a Summary Table for a Linear Model — model.summary.table","text":"function creates summary table linear model, including estimated coefficients, standard errors, p-values significance codes, model statistics MSE R-squared. table can output either LaTeX (PDF reports) plain text (console viewing).","code":""},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/model.summary.table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a Summary Table for a Linear Model — model.summary.table","text":"","code":"model.summary.table(model, caption, latex = TRUE)"},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/model.summary.table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a Summary Table for a Linear Model — model.summary.table","text":"model linear model object (typically result `lm()`). caption character string used caption table. latex Logical; `TRUE` (default), returns LaTeX-formatted table using `kableExtra`. `FALSE`, prints plain-text summary tables console.","code":""},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/model.summary.table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a Summary Table for a Linear Model — model.summary.table","text":"`latex = TRUE`, returns LaTeX-formatted `kableExtra` table object.         `latex = FALSE`, prints formatted summary tables console returns underlying data frame.","code":""},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/model.summary.table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a Summary Table for a Linear Model — model.summary.table","text":"","code":"# Fit a linear model model <- lm(mpg ~ wt + hp, data = mtcars)  # Print a plain-text version to the console model.summary.table(model, caption = \"Linear Model Summary\", latex = FALSE) #> == Linear Model Summary == #> Equation: mpg = 37.227 + -3.878*wt + -0.032*hp #>  #> Coefficient Table: #>  #>  #>               Term          Estimate   Std.Error   P.Value   Signif.  #> ------------  ------------  ---------  ----------  --------  -------- #> (Intercept)   (Intercept)   37.22727   1.59879     0         :3       #> wt            wt            -3.87783   0.63273     0         :3       #> hp            hp            -0.03177   0.00903     0.00145   :)       #> 1                                                                     #> 5                                                                     #>  #> Model Statistics: #>  #>  #> Statistic            Value #> ---------------  --------- #> MSE                6.09524 #> MSE adj.           6.72578 #> df                29.00000 #> R-squared          0.82679 #> R-squared adj.     0.81484"},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/pls.regression.html","id":null,"dir":"Reference","previous_headings":"","what":"Partial Least Squares (PLS) Regression Interface — pls.regression","title":"Partial Least Squares (PLS) Regression Interface — pls.regression","text":"Performs Partial Least Squares (PLS) regression using either NIPALS SVD algorithm component extraction. main user-facing function computing PLS models. Internally, delegates either NIPALS.pls() SVD.pls().","code":""},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/pls.regression.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Partial Least Squares (PLS) Regression Interface — pls.regression","text":"","code":"pls.regression(x, y, n.components = NULL, calc.method = c(\"SVD\", \"NIPALS\"))"},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/pls.regression.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Partial Least Squares (PLS) Regression Interface — pls.regression","text":"x numeric matrix data frame predictor variables (X), dimensions n × p. y numeric matrix data frame response variables (Y), dimensions n × q. n.components Integer specifying number latent components (H) extract. NULL, defaults rank x. calc.method Character string indicating algorithm use. Must either \"SVD\" (default) \"NIPALS\".","code":""},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/pls.regression.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Partial Least Squares (PLS) Regression Interface — pls.regression","text":"list (either SVD.pls() NIPALS.pls()) containing: model.type Character string (\"PLS Regression\"). T, U Score matrices X Y. W, C Weight matrices X Y. P_loadings, Q_loadings Loading matrices. B_vector Component-wise regression weights. coefficients Final regression coefficient matrix (rescaled). intercept Intercept vector (typically zero due centering). X_explained, Y_explained Variance explained component. X_cum_explained, Y_cum_explained Cumulative variance explained.","code":""},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/pls.regression.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Partial Least Squares (PLS) Regression Interface — pls.regression","text":"function provides unified interface Partial Least Squares regression. Based value calc.method, computes latent variables using either: \"SVD\" — direct method using singular value decomposition cross-covariance matrix (\\(X^\\top Y\\)). \"NIPALS\" — iterative method alternately estimates predictor response scores convergence. outputs methods include scores, weights, loadings, regression coefficients, explained variance.","code":""},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/pls.regression.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Partial Least Squares (PLS) Regression Interface — pls.regression","text":"Abdi, H., & Williams, L. J. (2013). Partial least squares methods: Partial least squares correlation partial least square regression. Methods Molecular Biology (Clifton, N.J.), 930, 549–579. doi:10.1007/978-1-62703-059-5_23 de Jong, S. (1993). SIMPLS: alternative approach partial least squares regression. Chemometrics Intelligent Laboratory Systems, 18(3), 251–263. doi:10.1016/0169-7439(93)85002-X","code":""},{"path":[]},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/pls.regression.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Partial Least Squares (PLS) Regression Interface — pls.regression","text":"","code":"if (FALSE) { # \\dontrun{ X <- matrix(rnorm(100 * 10), 100, 10) Y <- matrix(rnorm(100 * 2), 100, 2)  # Using SVD (default) model1 <- pls.regression(X, Y, n.components = 3)  # Using NIPALS model2 <- pls.regression(X, Y, n.components = 3, calc.method = \"NIPALS\") } # }"},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/pls.summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Format PLS Model Output as LaTeX or Console Tables — pls.summary","title":"Format PLS Model Output as LaTeX or Console Tables — pls.summary","text":"Formats displays Partial Least Squares (PLS) model output pls.regression() either LaTeX tables (PDF rendering) console-friendly output.","code":""},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/pls.summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format PLS Model Output as LaTeX or Console Tables — pls.summary","text":"","code":"pls.summary(x, ..., include.scores = TRUE, latex = TRUE)"},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/pls.summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format PLS Model Output as LaTeX or Console Tables — pls.summary","text":"x list returned pls.regression() (class \"pls\") containing PLS model components. ... arguments passed methods (unused). include.scores Logical. Whether include score matrices (T U). Default TRUE. latex Logical. TRUE, produces LaTeX output (PDF rendering). FALSE, prints console. Default FALSE.","code":""},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/pls.summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Format PLS Model Output as LaTeX or Console Tables — pls.summary","text":"latex = TRUE, returns knitr::asis_output object (LaTeX code).         latex = FALSE, prints formatted tables console returns NULL.","code":""},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/pls.summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Format PLS Model Output as LaTeX or Console Tables — pls.summary","text":"","code":"# Load example data data(mtcars)  # Prepare data for PLS regression X <- mtcars[, c(\"wt\", \"hp\", \"disp\")] Y <- mtcars[, \"mpg\", drop = FALSE]  # Fit PLS model with 2 components pls.fit <- pls.regression(X, Y, n.components = 2)  # Print a console-formatted summary pls.summary(pls.fit, latex = FALSE) #>  #>  #> Table: X Weights (W) #>  #> --------  -------- #>  -0.6025   -0.7868 #>  -0.5390    0.2773 #>  -0.5886    0.5515 #> --------  -------- #>  #>  #> Table: X Loadings (P) #>  #> --------  -------- #>  -5.1515   -2.0903 #>  -4.8773    1.9874 #>  -5.3940    0.3199 #> --------  -------- #>  #>  #> Table: Y Weights (C) #>  #>    x #>  --- #>    1 #>    1 #>  #>  #> Table: Y Loadings (Q) #>  #> ---  --- #>   1    1 #> ---  --- #>  #>  #> Table: Regression Scalars (b) #>  #>  Component   Estimate #> ----------  --------- #>          1     5.0114 #>          2     0.5793 #>  #>  #> Table: Regression Coefficients (Original Scale) #>  #>         Estimate #> -----  --------- #> wt       -2.9704 #> hp       -0.0144 #> disp     -0.0156 #>  #>  #> Table: X Scores (T) #>  #> --------  -------- #>   0.1114    0.0201 #>   0.0937   -0.0684 #>   0.1748    0.0026 #>   0.0180   -0.0085 #>  -0.1093    0.2026 #>   0.0231   -0.1614 #>  -0.1801    0.2697 #>   0.1214   -0.2787 #>   0.0982   -0.2227 #>   0.0392   -0.2298 #>   0.0392   -0.2298 #>  -0.1124   -0.1607 #>  -0.0889   -0.0427 #>  -0.0923   -0.0601 #>  -0.3206   -0.1741 #>  -0.3351   -0.2402 #>  -0.3322   -0.2250 #>   0.2226   -0.0522 #>   0.2770    0.1229 #>   0.2528    0.0591 #>   0.1548   -0.0193 #>  -0.0704    0.0586 #>  -0.0570    0.0627 #>  -0.1934    0.1579 #>  -0.1586    0.1347 #>   0.2407    0.0403 #>   0.1825    0.0842 #>   0.2199    0.2913 #>  -0.1644    0.4227 #>   0.0516    0.0450 #>  -0.2280    0.3070 #>   0.1220   -0.1078 #> --------  -------- #>  #>  #> Table: Y Scores (U) #>  #> --------  -------- #>   0.1509   -0.4072 #>   0.1509   -0.3189 #>   0.4495   -0.4266 #>   0.2173    0.1271 #>  -0.2307    0.3171 #>  -0.3303   -0.4459 #>  -0.9608   -0.0584 #>   0.7150    0.1065 #>   0.4495   -0.0426 #>  -0.1478   -0.3440 #>  -0.3801   -0.5763 #>  -0.6124   -0.0491 #>  -0.4630   -0.0176 #>  -0.8115   -0.3487 #>  -1.6079   -0.0011 #>  -1.6079    0.0714 #>  -0.8944    0.7704 #>   2.0424    0.9269 #>   1.7105    0.3225 #>   2.2913    1.0246 #>   0.2338   -0.5421 #>  -0.7617   -0.4090 #>  -0.8115   -0.5256 #>  -1.1267   -0.1575 #>  -0.1478    0.6472 #>   1.1962   -0.0103 #>   0.9805    0.0660 #>   1.7105    0.6088 #>  -0.7119    0.1119 #>  -0.0648   -0.3236 #>  -0.8446    0.2982 #>   0.2173   -0.3941 #> --------  -------- #>  #>  #> Table: Variance Explained by Components (X) #>  #>  Latent.Vector  Explained.Variance   Cumulative  #> --------------  -------------------  ----------- #>              1  85.3995%             85.3995%    #>              2  9.0554%              94.4549%    #>  #>  #> Table: Variance Explained by Components (Y) #>  #>  Latent.Vector  Explained.Variance   Cumulative  #> --------------  -------------------  ----------- #>              1  81.0145%             81.0145%    #>              2  1.0825%              82.0969%"},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/snazzieR.theme.html","id":null,"dir":"Reference","previous_headings":"","what":"A Custom ggplot2 Theme for Publication-Ready Plots — snazzieR.theme","title":"A Custom ggplot2 Theme for Publication-Ready Plots — snazzieR.theme","text":"theme provides clean, polished look ggplot2 plots, focus readability aesthetics. includes custom color palette formatting titles, axes, legends.","code":""},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/snazzieR.theme.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A Custom ggplot2 Theme for Publication-Ready Plots — snazzieR.theme","text":"","code":"snazzieR.theme()"},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/snazzieR.theme.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A Custom ggplot2 Theme for Publication-Ready Plots — snazzieR.theme","text":"ggplot2 theme object.","code":""},{"path":[]},{"path":"https://jesusbutforgaypeople.github.io/snazzieR/reference/snazzieR.theme.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A Custom ggplot2 Theme for Publication-Ready Plots — snazzieR.theme","text":"","code":"library(ggplot2) set.seed(123) chains.df <- data.frame(   Iteration = 1:500,   alpha.1 = cumsum(rnorm(500, mean = 0.01, sd = 0.2)) + rnorm(1, 5, 0.2),   alpha.2 = cumsum(rnorm(500, mean = 0.005, sd = 0.2)) + rnorm(1, 5, 0.2),   alpha.3 = cumsum(rnorm(500, mean = 0.000, sd = 0.2)) + rnorm(1, 5, 0.2),   alpha.4 = cumsum(rnorm(500, mean = -0.005, sd = 0.2)) + rnorm(1, 5, 0.2),   alpha.5 = cumsum(rnorm(500, mean = -0.01, sd = 0.2)) + rnorm(1, 5, 0.2) ) chain.colors <- c(\"Chain 1\" = Red, \"Chain 2\" = Orange, \"Chain 3\" = Yellow,                   \"Chain 4\" = Green, \"Chain 5\" = Blue) ggplot(chains.df, aes(x = Iteration)) +   geom_line(aes(y = alpha.1, color = \"Chain 1\"), linewidth = 1.2) +   geom_line(aes(y = alpha.2, color = \"Chain 2\"), linewidth = 1.2) +   geom_line(aes(y = alpha.3, color = \"Chain 3\"), linewidth = 1.2) +   geom_line(aes(y = alpha.4, color = \"Chain 4\"), linewidth = 1.2) +   geom_line(aes(y = alpha.5, color = \"Chain 5\"), linewidth = 1.2) +   labs(x = \"Iteration\", y = expression(alpha),        title = expression(\"Traceplot for \" ~ alpha)) +   scale_color_manual(values = chain.colors, name = \"Chains\") +   snazzieR.theme()"}]
